\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gelman2014bayesian,tenenbaum2006theory,mccullagh2002}
\citation{dayan1995helmholtz,mackay1997density}
\citation{uria2013rnade,rippel2013high,papamakarios2017masked}
\citation{Goodfellow:2014aa}
\citation{Kingma:2013aa,rezende2014stochastic,titsias2014doubly}
\citation{friedman2001elements}
\citation{zhou2018compressibility}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Kingma:2013aa}
\citation{wainwright2008graphical}
\citation{loaiza2017maximum}
\citation{gershman2014amortized,Kingma:2013aa,rezende2014stochastic,stuhlmuller2013learning}
\@writefile{toc}{\contentsline {section}{\numberline {2}Exponential family networks}{2}{section.2}}
\citation{Devroye:1986aa}
\citation{wainwright2008graphical}
\citation{robert2007bayesian}
\citation{mackay1995hierarchical}
\citation{teh2006hdp}
\citation{blei2003latent,pritchard2000inference}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (A) Graphical model for conditionally iid sampling from an exponential family likelihood. (B) Hierarchical Dirichlets -- prior $p_0(z)$ (top), three sample conditional Dirichlet datasets $X$ of $N=2, N=20, N=100$ (middle), and three corresponding posteriors that themselves form an exponential family $\mathcal  {P}$ (bottom). (C) Architecture for exponential family network (EFN) -- density network running top to bottom; parameter network running right to left.}}{3}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Exponential families as target model $\mathcal  {P}$}{3}{subsection.2.1}}
\newlabel{eq:1}{{1}{3}{Exponential families as target model $\mathcal {P}$}{equation.2.1}{}}
\citation{robert2007bayesian}
\citation{mackay1997density,baird2005one,tabak2010density,rippel2013high,uria2013rnade,rezende2015variational,dinh2016density,papamakarios2017masked,jacobsen2018revnet}
\citation{andrychowicz2016learning}
\citation{rezende2015variational}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Density networks as generic approximating family $\mathcal  {M}$}{4}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Exponential family networks as approximating model $\mathcal  {Q}$}{4}{subsection.2.3}}
\citation{papamakarios2015distilling}
\citation{Kingma:2013aa}
\citation{blei2003latent,blei2017variational}
\citation{Kingma:2013aa}
\citation{saul1996exploiting,barber1999tractable}
\citation{hoffman2015stochastic,tran2015copula}
\citation{rezende2015variational}
\citation{rezende2015variational}
\newlabel{eq:obj}{{2}{5}{Exponential family networks as approximating model $\mathcal {Q}$}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Relation to variational inference}{5}{subsection.2.4}}
\citation{robert2007bayesian}
\citation{rezende2015variational}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{6}{section.3}}
\citation{gretton2012kernel}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 25-dimensional Dirichlet exopnential family network. (A) Distribution of $r^2$ between log density of EFN samples and ground truth across choices of $\eta $ throughout optimization. (B) Distribution of KL divergence throughout optimization. (C) Distribution of maximum mean discrepancy p-values between EFN samples and ground truth after optimization.}}{7}{figure.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Scaling exponential family networks: $D$ denotes the dimensionality of the family being learned, and comparisons are between EFN and its $K=1$ alternatives NF1 and EFN1 (see text). (A) Dirichlet family (B) Gaussian family (C) Inverse-Wishart family.}}{7}{figure.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tractable exponential families}{7}{subsection.3.1}}
\citation{teh2006hdp}
\citation{mackay1995hierarchical}
\citation{blei2003latent,pritchard2000inference}
\citation{gao2016linear}
\citation{adams2009tractable}
\citation{cunningham2008fast,cunningham2008inferring}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Scaling Dir-Dir}}{8}{figure.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Intractable exponential families}{8}{subsection.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical Dirichlets}{8}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Truncated- and log-normal Poisson}{8}{section*.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Neural spike train analysis}{8}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{9}{section.4}}
\bibstyle{unsrt}
\bibdata{BittnerNIPS2018}
\bibcite{gelman2014bayesian}{{1}{}{{}}{{}}}
\bibcite{tenenbaum2006theory}{{2}{}{{}}{{}}}
\bibcite{mccullagh2002}{{3}{}{{}}{{}}}
\bibcite{dayan1995helmholtz}{{4}{}{{}}{{}}}
\bibcite{mackay1997density}{{5}{}{{}}{{}}}
\bibcite{uria2013rnade}{{6}{}{{}}{{}}}
\bibcite{rippel2013high}{{7}{}{{}}{{}}}
\bibcite{papamakarios2017masked}{{8}{}{{}}{{}}}
\bibcite{Goodfellow:2014aa}{{9}{}{{}}{{}}}
\bibcite{Kingma:2013aa}{{10}{}{{}}{{}}}
\bibcite{rezende2014stochastic}{{11}{}{{}}{{}}}
\bibcite{titsias2014doubly}{{12}{}{{}}{{}}}
\bibcite{friedman2001elements}{{13}{}{{}}{{}}}
\bibcite{zhou2018compressibility}{{14}{}{{}}{{}}}
\bibcite{wainwright2008graphical}{{15}{}{{}}{{}}}
\bibcite{loaiza2017maximum}{{16}{}{{}}{{}}}
\bibcite{gershman2014amortized}{{17}{}{{}}{{}}}
\bibcite{stuhlmuller2013learning}{{18}{}{{}}{{}}}
\bibcite{Devroye:1986aa}{{19}{}{{}}{{}}}
\bibcite{robert2007bayesian}{{20}{}{{}}{{}}}
\bibcite{mackay1995hierarchical}{{21}{}{{}}{{}}}
\bibcite{teh2006hdp}{{22}{}{{}}{{}}}
\bibcite{blei2003latent}{{23}{}{{}}{{}}}
\bibcite{pritchard2000inference}{{24}{}{{}}{{}}}
\bibcite{baird2005one}{{25}{}{{}}{{}}}
\bibcite{tabak2010density}{{26}{}{{}}{{}}}
\bibcite{rezende2015variational}{{27}{}{{}}{{}}}
\bibcite{dinh2016density}{{28}{}{{}}{{}}}
\bibcite{jacobsen2018revnet}{{29}{}{{}}{{}}}
\bibcite{andrychowicz2016learning}{{30}{}{{}}{{}}}
\bibcite{papamakarios2015distilling}{{31}{}{{}}{{}}}
\bibcite{blei2017variational}{{32}{}{{}}{{}}}
\bibcite{saul1996exploiting}{{33}{}{{}}{{}}}
\bibcite{barber1999tractable}{{34}{}{{}}{{}}}
\bibcite{hoffman2015stochastic}{{35}{}{{}}{{}}}
\bibcite{tran2015copula}{{36}{}{{}}{{}}}
\bibcite{gretton2012kernel}{{37}{}{{}}{{}}}
\bibcite{gao2016linear}{{38}{}{{}}{{}}}
\bibcite{adams2009tractable}{{39}{}{{}}{{}}}
\bibcite{cunningham2008fast}{{40}{}{{}}{{}}}
\bibcite{cunningham2008inferring}{{41}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
