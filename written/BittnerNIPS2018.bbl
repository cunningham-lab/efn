\begin{thebibliography}{10}

\bibitem{gelman2014bayesian}
Andrew Gelman, John~B Carlin, Hal~S Stern, David~B Dunson, Aki Vehtari, and
  Donald~B Rubin.
\newblock {\em Bayesian data analysis}, volume~2.
\newblock CRC press Boca Raton, FL, 2014.

\bibitem{tenenbaum2006theory}
Joshua~B Tenenbaum, Thomas~L Griffiths, and Charles Kemp.
\newblock Theory-based bayesian models of inductive learning and reasoning.
\newblock {\em Trends in cognitive sciences}, 10(7):309--318, 2006.

\bibitem{mccullagh2002}
Peter McCullagh.
\newblock What is a statistical model?
\newblock {\em The Annals of Statistics}, 30(5):1225--1267, 2002.

\bibitem{dayan1995helmholtz}
Peter Dayan, Geoffrey~E Hinton, Radford~M Neal, and Richard~S Zemel.
\newblock The helmholtz machine.
\newblock {\em Neural computation}, 7(5):889--904, 1995.

\bibitem{mackay1997density}
D.~J.~C. MacKay and M.~N. Gibbs.
\newblock Density networks.
\newblock In {\em Statistics and Neural Networks}, pages 129--146. Oxford,
  1997.

\bibitem{uria2013rnade}
Benigno Uria, Iain Murray, and Hugo Larochelle.
\newblock Rnade: The real-valued neural autoregressive density-estimator.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2175--2183, 2013.

\bibitem{rippel2013high}
Oren Rippel and Ryan~Prescott Adams.
\newblock High-dimensional probability estimation with deep density models.
\newblock {\em arXiv preprint arXiv:1302.5125}, 2013.

\bibitem{papamakarios2017masked}
George Papamakarios, Iain Murray, and Theo Pavlakou.
\newblock Masked autoregressive flow for density estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2335--2344, 2017.

\bibitem{Goodfellow:2014aa}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~D. Lawrence, and K.~Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems
  27}, pages 2672--2680. Curran Associates, Inc., 2014.

\bibitem{Kingma:2013aa}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv}, 12 2013.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em arXiv preprint arXiv:1401.4082}, 2014.

\bibitem{titsias2014doubly}
Michalis Titsias and Miguel L{\'a}zaro-Gredilla.
\newblock Doubly stochastic variational bayes for non-conjugate inference.
\newblock In {\em International Conference on Machine Learning}, pages
  1971--1979, 2014.

\bibitem{friedman2001elements}
Trevor Hastie, Robert Tibshirani, and Jerome Friedman.
\newblock {\em The elements of statistical learning}, volume~1.
\newblock Springer series in statistics New York, 2001.

\bibitem{zhou2018compressibility}
Wenda Zhou, Victor Veitch, Morgane Austern, Ryan~P Adams, and Peter Orbanz.
\newblock Compressibility and generalization in large-scale deep learning.
\newblock {\em arXiv preprint arXiv:1804.05862}, 2018.

\bibitem{wainwright2008graphical}
Martin~J Wainwright, Michael~I Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  1(1--2):1--305, 2008.

\bibitem{hinton1995wake}
Geoffrey~E Hinton, Peter Dayan, Brendan~J Frey, and Radford~M Neal.
\newblock The" wake-sleep" algorithm for unsupervised neural networks.
\newblock {\em Science}, 268(5214):1158--1161, 1995.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em arXiv preprint arXiv:1505.05770}, 2015.

\bibitem{baird2005one}
Leemon Baird, David Smalenberger, and Shawn Ingkiriwang.
\newblock One-step neural network inversion with pdf learning and emulation.
\newblock In {\em Neural Networks, 2005. IJCNN'05. Proceedings. 2005 IEEE
  International Joint Conference on}, volume~2, pages 966--971. IEEE, 2005.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{jacobsen2018revnet}
J{\"o}rn-Henrik Jacobsen, Arnold Smeulders, and Edouard Oyallon.
\newblock i-revnet: Deep invertible networks.
\newblock {\em arXiv preprint arXiv:1802.07088}, 2018.

\bibitem{chen2001gaussianization}
Scott~Saobing Chen and Ramesh~A Gopinath.
\newblock Gaussianization.
\newblock In {\em Advances in neural information processing systems}, pages
  423--429, 2001.

\bibitem{tabak2010density}
Esteban~G Tabak, Eric Vanden-Eijnden, et~al.
\newblock Density estimation by dual ascent of the log-likelihood.
\newblock {\em Communications in Mathematical Sciences}, 8(1):217--233, 2010.

\bibitem{saul1996exploiting}
Lawrence~K Saul and Michael~I Jordan.
\newblock Exploiting tractable substructures in intractable networks.
\newblock In {\em Advances in neural information processing systems}, pages
  486--492, 1996.

\bibitem{barber1999tractable}
David Barber and Wim Wiegerinck.
\newblock Tractable variational structures for approximating graphical models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  183--189, 1999.

\bibitem{hoffman2015stochastic}
Matthew Hoffman and David Blei.
\newblock Stochastic structured variational inference.
\newblock In {\em Artificial Intelligence and Statistics}, pages 361--369,
  2015.

\bibitem{tran2015copula}
Dustin Tran, David Blei, and Edo~M Airoldi.
\newblock Copula variational inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3564--3572, 2015.

\bibitem{robert2007bayesian}
Christian Robert.
\newblock {\em The Bayesian choice: from decision-theoretic foundations to
  computational implementation}.
\newblock Springer Science \& Business Media, 2007.

\bibitem{andrychowicz2016learning}
Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew~W Hoffman, David Pfau,
  Tom Schaul, and Nando de~Freitas.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3981--3989, 2016.

\bibitem{loaiza2017maximum}
Gabriel Loaiza-Ganem, Yuanjun Gao, and John~P Cunningham.
\newblock Maximum entropy flow networks.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{papamakarios2015distilling}
George Papamakarios and Iain Murray.
\newblock Distilling intractable generative models.
\newblock In {\em Probabilistic Integration Workshop at Neural Information
  Processing Systems}, 2015.

\bibitem{hoffman2016elbo}
Matthew~D Hoffman and Matthew~J Johnson.
\newblock Elbo surgery: yet another way to carve up the variational evidence
  lower bound.
\newblock In {\em Workshop in Advances in Approximate Bayesian Inference,
  NIPS}, 2016.

\bibitem{cremer2018inference}
Chris Cremer, Xuechen Li, and David Duvenaud.
\newblock Inference suboptimality in variational autoencoders.
\newblock {\em arXiv preprint arXiv:1801.03558}, 2018.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em Journal of Machine Learning Research}, 13(Mar):723--773, 2012.

\bibitem{teh2006hdp}
Yee~Whye Teh, Michael~I Jordan, Matthew~J Beal, and David~M Blei.
\newblock Hierarchical dirichlet processes.
\newblock {\em Journal of the American Statistical Association},
  101(476):1566--1581, 2006.

\bibitem{mackay1995hierarchical}
David~JC MacKay and Linda C~Bauman Peto.
\newblock A hierarchical dirichlet language model.
\newblock {\em Natural language engineering}, 1(3):289--308, 1995.

\bibitem{blei2003latent}
David~M Blei, Andrew~Y Ng, and Michael~I Jordan.
\newblock Latent dirichlet allocation.
\newblock {\em Journal of machine Learning research}, 3(Jan):993--1022, 2003.

\bibitem{pritchard2000inference}
Jonathan~K Pritchard, Matthew Stephens, and Peter Donnelly.
\newblock Inference of population structure using multilocus genotype data.
\newblock {\em Genetics}, 155(2):945--959, 2000.

\bibitem{gao2016linear}
Yuanjun Gao, Evan~W Archer, Liam Paninski, and John~P Cunningham.
\newblock Linear dynamical neural population models through nonlinear
  embeddings.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  163--171, 2016.

\bibitem{adams2009tractable}
Ryan~Prescott Adams, Iain Murray, and David~JC MacKay.
\newblock Tractable nonparametric bayesian inference in poisson processes with
  gaussian process intensities.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 9--16. ACM, 2009.

\bibitem{cunningham2008fast}
John~P Cunningham, Krishna~V Shenoy, and Maneesh Sahani.
\newblock Fast gaussian process methods for point process intensity estimation.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 192--199. ACM, 2008.

\bibitem{cunningham2008inferring}
John~P Cunningham, M~Yu Byron, Krishna~V Shenoy, and Maneesh Sahani.
\newblock Inferring neural firing rates from spike trains using gaussian
  processes.
\newblock In {\em Advances in neural information processing systems}, pages
  329--336, 2008.

\end{thebibliography}
